# -*- coding: utf-8 -*-
"""HP - MAT 220 Python Project 3 (Least-Squares Regression).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KW5qkkWBxYcI3w7dstYfzT7prWzltyTH

# Python Project 3: Least-Squares Regression

Reference pages 99 - 101 (Section 2.6 of textbook) (Subsection "Least Squares Regression Analysis")

As you saw in Section 2.6 notes, in the "real world", we often have data that has an imperfect relationship. This led us to using the points to create a line of "best fit."

## Example

Consider the data points:
(5,8), (6,10), (6,12), (7,12), (8,14), (9,15), (10,18)

First, import libraries and define sympy variables:
"""

from sympy import *
init_printing()
x, y, z, t = symbols('x y z t')
k, m, n = symbols('k m n', integer=True)
f, g, h = symbols('f g h', cls=Function)

import matplotlib.pyplot as plt
import numpy as np
from sympy.plotting.plot import MatplotlibBackend, Plot

"""Now we make an array (in "numpy") of the x-coordinates called $r$ and an array of the y-coordinates called $s$, and plot them (using "matplotlib") in a scatterplot."""

r = np.array([5,6,6,7,8,9,10])
s = np.array([8,10,12,12,14,15,18])
plt.plot(r, s, 'o')

"""Note that the points are not collinear, but that there is roughly a linear relationship between x and y.  So, it makes sense to find the least squares regression line.  We now use Python to define the matrices:

$X = \begin{bmatrix}
1 & 5 \\
1 & 6 \\
1 & 6 \\
1 & 7 \\
1 & 8 \\
1 & 9 \\
1 & 10 \\
\end{bmatrix}$

and

$Y = \begin{bmatrix}
8 \\
10 \\
12 \\
12 \\
14 \\
15 \\
18 \\
\end{bmatrix}$
"""

X = Matrix([[1,5],[1,6],[1,6],[1,7],[1,8],[1,9],[1,10]])
Y = Matrix([8,10,12,12,14,15,18])

"""Next, we use Python to compute: $A = (X^T X)^{-1} X^T Y$"""

A = (X.T*X)**-1*X.T*Y
pprint(A)

"""So, the least-squares regression line is: $\hat{y} = -\frac{1}{4} + \frac{121}{68} x$

Now, letâ€™s plot the regression line with the scatterplot.
"""

best_fit_line = 121/68*r + -1/4

plt.scatter(r, s, label = "Data")
plt.plot(r,best_fit_line,color='red',label = "Best Fit Line")
plt.xlim([0,12])
plt.ylim([0,22])
plt.show()

"""We can also find the sum of squared error by computing $E^T E$ where $E = Y-XA$:"""

E = Y - X*A
pprint(E.T*E)

"""We see that the sum of squared error is $\frac{133}{34}$.

## Directions

+ You must use methods from our class. Do not use new code methods or write your own. I am checking that you are using the built-in features, including the matrices.
+ Do not use other AI programs or create new functions that are not given.  Again, do not use new code methods or write your own.
+ Make sure you run each code cell with appropriate output visible. You must include all of the matrices in the appropriate place in your document.

For each problem below (in this order):

1. Given the data points, make a scatter plot. Does there seem to be a rough linear relationship between $x$ and $y$? **If not, stop here.** <br>*Note: Imagine drawing "railroad rails" that enclose the data. In general, would the rails be straight, or would they need to curve?*
1. Find an equation of the least squares regression line.
1. Graph your regression line with the scatterplot. Be sure to adjust your axes to fit your points.
1. Find the sum of squared error for the least squares regression line.

## Problem 1

Points: (1,24), (2,21), (3,19), (4,16), (5,14)
"""

from sympy import *
init_printing()
x, y, z, t = symbols('x y z t')
k, m, n = symbols('k m n', integer=True)
f, g, h = symbols('f g h', cls=Function)

import matplotlib.pyplot as plt
import numpy as np
from sympy.plotting.plot import MatplotlibBackend, Plot

r = np.array([1,2,3,4,5])
s = np.array([24, 21, 19, 16, 14])
plt.plot(r, s, 'o')

# Define matrices X and Y
X = Matrix([[1,1],[1,2],[1,3],[1,4],[1,5]])
Y = Matrix([24, 21, 19, 16, 14])
pprint(X)
pprint(Y)

# Calculate A = (X^T X)^-1 X^T Y
A = (X.T*X)**-1*X.T*Y
pprint(A)

"""So, the least-squares regression line is: $\hat{y} = -\frac{263}{10} + \frac{5}{2} x$"""

# Plot regression line with scatter
best_fit_line = A[1] * r + A[0]

plt.scatter(r, s, label = "Data")
plt.plot(r, best_fit_line, color='red', label = "Best Fit Line")
plt.xlim([0, 6])
plt.ylim([10, 30])
plt.legend()
plt.show()

# Calculate sum of squared error
E = Y - X * A
pprint(E.T * E)

"""## Problem 2

Points: (10,3), (12,7), (13,9), (14,10), (15,8), (17,2), (18,0)
"""

from sympy import *
init_printing()
x, y, z, t = symbols('x y z t')
k, m, n = symbols('k m n', integer=True)
f, g, h = symbols('f g h', cls=Function)

import matplotlib.pyplot as plt
import numpy as np
from sympy.plotting.plot import MatplotlibBackend, Plot

r = np.array([10, 12, 13, 14, 15, 17, 18])
s = np.array([3, 7, 9, 10, 8, 2, 0])
plt.plot(r, s, 'o')

# Define matrices X and Y
X = Matrix([[1,10], [1,12], [1,13], [1,14], [1,15], [1,17], [1,18]])
Y = Matrix([3, 7, 9, 10, 8, 2, 0])
pprint(X)
pprint(Y)

# Calculate A = (X^T X)^-1 X^T Y
A = (X.T * X)**-1 * X.T * Y
pprint(A)

# Plot regression line with scatter
best_fit_line = A[1] * r + A[0]

plt.scatter(r, s, label = "Data")
plt.plot(r, best_fit_line, color='red', label = "Best Fit Line")
plt.xlim([9, 19])
plt.ylim([-2, 12])
plt.legend()
plt.show()

# Calculate sum of squared error
E = Y - X * A
pprint(E.T * E)

"""*This graph doesnt seem to have much of a linear relationship. But I wanted to see how it would play out so the code is above. Its technically x^3 but since all points are not collaboratively linear, we should skip.

## Problem 3

Points: (-2,5), (-1,8), (13,9), (14,10), (15,8), (17,2), (18,0)
"""

from sympy import *
init_printing()
x, y, z, t = symbols('x y z t')
k, m, n = symbols('k m n', integer=True)
f, g, h = symbols('f g h', cls=Function)

import matplotlib.pyplot as plt
import numpy as np
from sympy.plotting.plot import MatplotlibBackend, Plot

r = np.array([-2, -1, 13, 14, 15, 17, 18])
s = np.array([5, 8, 9, 10, 8, 2, 0])
plt.plot(r, s, 'o')

"""*This graph doesnt seem to have much of a linear relationship. So skip.

## Problem 4

The table below shows the relationship between the percent of adult males unemployed and the percent of adult females unemployed.

| % Adult Males | % Adult Females |
|---------------|-----------------|
| 2.9           | 4.0             |
| 6.7           | 7.4             |
| 4.9           | 5.0             |
| 7.9           | 7.2             |
| 9.8           | 7.9             |
| 6.9           | 6.1             |
| 6.1           | 6.0             |
| 6.2           | 5.8             |
| 6.0           | 5.2             |
| 5.1           | 4.2             |
| 4.7           | 4.0             |
| 4.4           | 4.4             |
| 5.8           | 5.2             |

Points:
[2.9, 4.0], [6.7, 7.4], [4.9, 5.0], [7.9, 7.2], [9.8, 7.9],
[6.9, 6.1], [6.1, 6.0], [6.2, 5.8], [6.0, 5.2], [5.1, 4.2],
[4.7, 4.0], [4.4, 4.4], [5.8, 5.2]
"""

from sympy import *
init_printing()
x, y, z, t = symbols('x y z t')
k, m, n = symbols('k m n', integer=True)
f, g, h = symbols('f g h', cls=Function)

import matplotlib.pyplot as plt
import numpy as np
from sympy.plotting.plot import MatplotlibBackend, Plot

# Define data arrays
r = np.array([2.9, 6.7, 4.9, 7.9, 9.8, 6.9, 6.1, 6.2, 6.0, 5.1, 4.7, 4.4, 5.8])
s = np.array([4.0, 7.4, 5.0, 7.2, 7.9, 6.1, 6.0, 5.8, 5.2, 4.2, 4.0, 4.4, 5.2])
plt.plot(r, s, 'o')

# Define matrices X and Y
X = Matrix([[1, i] for i in r])
Y = Matrix(list(s))
pprint(X)
pprint(Y)

# Calculate A = (X^T X)^-1 X^T Y
A = (X.T * X)**-1 * X.T * Y
pprint(A)

"""So, the least-squares regression line is: $\hat{y} = {1.43411072362684} + {0.694529206625983} x$"""

# Plot regression line with scatter
best_fit_line = A[1] * r + A[0]

plt.scatter(r, s, label = "Data")
plt.plot(r, best_fit_line, color='red', label = "Best Fit Line")
plt.xlim([2, 11])
plt.ylim([3, 9])
plt.legend()
plt.show()

# Calculate sum of squared error
E = Y - X * A
pprint(E.T * E)